{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet Transform interactive notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO list\n",
    "\n",
    "Here are the few things to improve in this notebook:\n",
    "\n",
    "- [ ] **improve the colormap and/or use the radius to distinguish background to signal**\n",
    "- [ ] add a colorbar\n",
    "- [ ] add the possibility to get images id to plot from a (file automatically made from others notebooks)\n",
    "- [ ] highlight pixels option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required modules and set some variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires PyWI and PyWI-CTA for the I/O and for the signal processing. It also requires Bokeh to display images (as a much faster alternative to Matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#from bokeh.plotting import figure, output_notebook, show    # For fix images\n",
    "\n",
    "import bokeh\n",
    "\n",
    "from bokeh.io import push_notebook, output_notebook, show    # For animations\n",
    "from bokeh.plotting import figure, ColumnDataSource          # For animations\n",
    "\n",
    "from bokeh.models import LogColorMapper, LogTicker, ContinuousColorMapper, ContinuousTicker, ColorBar\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "from bokeh.models.annotations import Title\n",
    "\n",
    "import matplotlib as mpl\n",
    "import math\n",
    "\n",
    "import os\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "import astropy.units as u\n",
    "\n",
    "import pywi\n",
    "import pywicta\n",
    "from pywicta.io import geometry_converter\n",
    "from pywicta.io.images import image_generator\n",
    "from pywicta.io.images import plot_ctapipe_image\n",
    "from pywicta.io.images import plot_hillas_parameters_on_axes\n",
    "from pywicta.io.images import get_mars_like_default_integrator_config\n",
    "from pywicta.image.hillas_parameters import get_hillas_parameters\n",
    "from pywicta.denoising.rejection_criteria import CTAMarsCriteria\n",
    "\n",
    "from pywicta.denoising import wavelets_mrtransform\n",
    "from pywicta.denoising.wavelets_mrtransform import WaveletTransform\n",
    "from pywicta.denoising import inverse_transform_sampling\n",
    "from pywicta.denoising.inverse_transform_sampling import EmpiricalDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether or not a ramdisk can be used to speedup wavelet transform processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ramdisk is a file storage space located in RAM.\n",
    "PyWI use intermediate files to make the wavelet transform, putting those files in a ramdisk makes the process much faster.\n",
    "Use [the following script](https://github.com/jeremiedecock/pywi-cta/blob/master/utils/ramdisk_macosx.sh) to make a ramdisk (MacOSX only):\n",
    "\n",
    "    ramdisk_macosx.sh create 32\n",
    "\n",
    "This creates a ramdisk reachable from `/Volumes/ramdisk`.\n",
    "\n",
    "On most Linux distributions, a ramdisk is already mounted by default in `/dev/shm` thus Linux users should directly set `RAMDISK_PATH = \"/dev/shm\"` in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAMDISK_PATH = \"/Volumes/ramdisk\"\n",
    "\n",
    "if os.path.isdir(RAMDISK_PATH):\n",
    "    print(\"Use ramdisk\")\n",
    "    TMP_DIR = RAMDISK_PATH\n",
    "else:\n",
    "    print(RAMDISK_PATH + \" IS NOT MOUNTED; RAMDISK WON'T BE USED FOR TEMPORARY FILES.\")\n",
    "    TMP_DIR = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the number of scales for the Wavelet transform algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_NUM_SCALES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cells define the list of images to use in this notebook.\n",
    "\n",
    "Images can be fetched from Fits files or from Simtel files.\n",
    "Fits files are much lighter and much faster to process than Simtel files but they are specific to PyWI-CTA and thus you first have to generate them from Simtel files using [the following script](). Also, contrary to Simtel files, a Fits files contains only one \"image\" (i.e. an unique event viewed from one unique telescope).\n",
    "\n",
    "The others things to configure are:\n",
    "\n",
    "1. `CAM_ID` to define the camera to use:  ASTRICam, CHEC, DigiCam, FlashCam, NectarCam or LSTCam.\n",
    "2. `IMG_ID_LIST` to fetch specific images e.g. set `IMG_ID_LIST = [ \"run104_2081200_1\", \"run105_1244901_4\"]` if you only want the image of the event `2081200` from telescope `1` in run `104` and the image of the event `1244901` from telescope `4` in run `105`.\n",
    "\n",
    "Alternatively, one can set `TEL_FILTER_LIST` and/or `EVENT_FILTER_LIST` to set the list of desired telescopes (e.g. `TEL_FILTER_LIST = [1, 3, 4]`) and the list of desired events (e.g. `EVENT_FILTER_LIST = [2081200, 1244901]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAM_ID = \"ASTRICam\"\n",
    "#CAM_ID = \"CHEC\"\n",
    "#CAM_ID = \"DigiCam\"\n",
    "#CAM_ID = \"FlashCam\"\n",
    "#CAM_ID = \"NectarCam\"\n",
    "CAM_ID = \"LSTCam\"\n",
    "\n",
    "IMG_ID_LIST = [\n",
    "    \"run104_2081200_1\",\n",
    "    \"run105_1244901_4\",\n",
    "]\n",
    "IMG_ID_LIST = []\n",
    "\n",
    "TEL_FILTER_LIST = []\n",
    "EVENT_FILTER_LIST = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(IMG_ID_LIST) > 0:\n",
    "    \n",
    "    # Use only the images defined in IMG_ID_LIST\n",
    "    # Take them from FITS_DIR if SIMTEL_DIR is True else take them from SIMTEL_DIR\n",
    "    \n",
    "    USE_FITS = True\n",
    "    FITS_DIR = \"dataset\"\n",
    "    SIMTEL_DIR = \"dataset\"\n",
    "    #FITS_DIR = \"~/data/grid_prod3b_north/fits/lst/gamma\"\n",
    "    #SIMTEL_DIR = \"~/data/grid_prod3b_north/simtel/gamma\"\n",
    "\n",
    "    PATHS = []\n",
    "    for img_id in IMG_ID_LIST:\n",
    "        run_id, event_id, tel_id = img_id.split(\"_\")\n",
    "        \n",
    "        run_id = int(run_id[3:])\n",
    "        event_id = int(event_id)\n",
    "        tel_id = int(tel_id)\n",
    "        \n",
    "        if USE_FITS:\n",
    "            PATHS.append(\"{}/gamma_20deg_0deg_run{}___cta-prod3-lapalma3-2147m-LaPalma.simtel.gz_TEL{:03d}_EV{}.fits\".format(FITS_DIR, run_id, tel_id, event_id))\n",
    "        else:\n",
    "            PATHS.append(\"{}/gamma_20deg_0deg_run{}___cta-prod3-lapalma3-2147m-LaPalma.simtel.gz\".format(SIMTEL_DIR, run_id))\n",
    "            TEL_FILTER_LIST.append(tel_id)\n",
    "            EVENT_FILTER_LIST.append(event_id)\n",
    "            \n",
    "    NUM_IMAGES = None     # The maximum number of images to load\n",
    "                \n",
    "else:\n",
    "    \n",
    "    # Use the N first images in the following files\n",
    "    \n",
    "    #SIMTEL_FILE = \"~/data/astri_mini_array_konrad/simtel/astri_v2/gamma/gamma_20deg_180deg_run2203___cta-prod3-sst-astri_desert-2150m-Paranal-sst-astri2.simtel.gz\"\n",
    "    #SIMTEL_FILE = \"~/data/gct_mini_array_konrad/simtel/gct/gamma/gamma_20deg_180deg_run2203___cta-prod3-sst-gct_desert-2150m-Paranal-sst-gct.simtel.gz\"\n",
    "    #SIMTEL_FILE = \"~/data/sst1m_mini_array_konrad/simtel/sst1m/gamma/gamma_20deg_180deg_run2203___cta-prod3-sst-dc_desert-2150m-Paranal-sst-dc.simtel.gz\"\n",
    "    SIMTEL_FILE = \"~/data/grid_prod3b_north/simtel/gamma/gamma_20deg_0deg_run104___cta-prod3-lapalma3-2147m-LaPalma.simtel.gz\"\n",
    "    PATHS = [SIMTEL_FILE]\n",
    "    \n",
    "    NUM_IMAGES = 30     # The maximum number of images to load\n",
    "    \n",
    "print(PATHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define preselection cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rejection_criteria` defines a function to apply a preselection cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rejection_criteria = lambda ref_image: not 200 < np.nansum(ref_image) < 250\n",
    "rejection_criteria = CTAMarsCriteria(cam_id=CAM_ID)\n",
    "#rejection_criteria = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrator_config_dict = get_mars_like_default_integrator_config(CAM_ID)\n",
    "\n",
    "image_dict = {\"run{}_{}_{}\".format(int(image.meta['run_id']),\n",
    "                                   int(image.meta['event_id']),\n",
    "                                   int(image.meta['tel_id'])): image\n",
    "              for image\n",
    "              in image_generator(PATHS,\n",
    "                                 max_num_images=NUM_IMAGES,\n",
    "                                 cam_filter_list=[CAM_ID],\n",
    "                                 tel_filter_list=TEL_FILTER_LIST,\n",
    "                                 ev_filter_list=EVENT_FILTER_LIST,\n",
    "                                 ctapipe_format=False,\n",
    "                                 mc_rejection_criteria=rejection_criteria,\n",
    "                                 **integrator_config_dict)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the image list for the widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(IMG_ID_LIST) > 0:\n",
    "    image_dict = {k: v for k, v in image_dict.items() if k in IMG_ID_LIST}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_1 = bokeh.palettes.Viridis256\n",
    "palette_2 = bokeh.palettes.Viridis256\n",
    "\n",
    "palette_2[0] = \"#eeeeee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mapper = bokeh.models.mappers.LinearColorMapper(palette=palette_1,\n",
    "                                                      low=0,\n",
    "                                                      high=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hillas_parameters(geom,\n",
    "                           image=None,\n",
    "                           hillas_params=None,\n",
    "                           hillas_implementation=2):\n",
    "    \"\"\"Plot the shower ellipse and direction on bokeh.\"\"\"\n",
    "    \n",
    "    centroid = (0, 0)\n",
    "    angle = 0.\n",
    "    length = 0.\n",
    "    width = 0.\n",
    "    lines_xs = [[0, 0], [0, 0]]\n",
    "    lines_ys = [[0, 0], [0, 0]]\n",
    "\n",
    "    try:\n",
    "        if hillas_params is None and image is not None:\n",
    "            hillas_params = get_hillas_parameters(geom, image, implementation=hillas_implementation)\n",
    "\n",
    "            centroid = (hillas_params.cen_x.value, hillas_params.cen_y.value)\n",
    "            length = hillas_params.length.value\n",
    "            width = hillas_params.width.value\n",
    "            angle = hillas_params.psi.to(u.rad).value\n",
    "\n",
    "            #print(\"centroid:\", centroid)\n",
    "            #print(\"length:\",   length)\n",
    "            #print(\"width:\",    width)\n",
    "            #print(\"angle:\",    angle)\n",
    "\n",
    "            p0_x = centroid[0]\n",
    "            p0_y = centroid[1]\n",
    "\n",
    "            p1_x = p0_x + math.cos(angle)\n",
    "            p1_y = p0_y + math.sin(angle)\n",
    "\n",
    "            p2_x = p0_x + math.cos(angle + math.pi)\n",
    "            p2_y = p0_y + math.sin(angle + math.pi)\n",
    "\n",
    "            lines_xs = [[p1_x, p2_x], [0, p0_x]]\n",
    "            lines_ys = [[p1_y, p2_y], [0, p0_y]]\n",
    "\n",
    "    except HillasParameterizationError as err:\n",
    "        print(err)\n",
    "    \n",
    "    return centroid, angle, length, width, lines_xs, lines_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make the cleaning class\n",
    "wavelet = WaveletTransform()\n",
    "\n",
    "# Get empirical noise distribution\n",
    "noise_cdf_file = inverse_transform_sampling.get_cdf_file_path(CAM_ID)  # pywicta.denoising.cdf.LSTCAM_CDF_FILE\n",
    "print(noise_cdf_file)\n",
    "empirical_noise_distribution = EmpiricalDistribution(noise_cdf_file)\n",
    "\n",
    "# Prepare plots\n",
    "geom1d = geometry_converter.get_geom1d(CAM_ID)\n",
    "\n",
    "# Prepare Bokeh plot\n",
    "if geom1d.pix_type == 'hexagonal':\n",
    "    radius = math.sqrt(geom1d.pix_area.value[0]/(2. * math.sqrt(3.))) # assuming an hexagon (see:https://fr.wikipedia.org/wiki/Hexagone#Calcul_de_l'aire)\n",
    "elif geom1d.pix_type == 'rectangular':\n",
    "    radius = math.sqrt(geom1d.pix_area.value[0]) / 2.\n",
    "else:\n",
    "    raise NotImplementedError(\"Unknown camera type {}\".format(geom1d.pix_type))\n",
    "    \n",
    "\n",
    "hover = HoverTool(\n",
    "            tooltips=[\n",
    "                (\"PE\", \"@pe\"),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize Bokeh (the display library) #################\n",
    "\n",
    "TOOLS = \"crosshair,pan,wheel_zoom,box_zoom,reset,tap,previewsave,box_select,poly_select,lasso_select\"\n",
    "\n",
    "CAM_SIZE = max(geom1d.pix_x.value.max(), geom1d.pix_y.value.max()) * 1.05\n",
    "\n",
    "FIGURE_SIZE = 600\n",
    "#fig = figure(plot_width=FIGURE_SIZE, plot_height=FIGURE_SIZE, tools=TOOLS)\n",
    "fig = figure(plot_width=FIGURE_SIZE,\n",
    "             plot_height=FIGURE_SIZE,\n",
    "             x_range=(-CAM_SIZE, CAM_SIZE),\n",
    "             y_range=(-CAM_SIZE, CAM_SIZE))\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "#colors = data_to_colors(img)\n",
    "\n",
    "title = Title()\n",
    "title.text = \"-\"\n",
    "fig.title = title\n",
    "\n",
    "## add a circle renderer with a size, color, and alpha\n",
    "#circles = fig.circle(geom1d.pix_x.value,\n",
    "#                     geom1d.pix_y.value,\n",
    "#                     #size=5,              # The size (diameter) values for the markers **in screen space units** (i.e. aspect changes with figure size or zoom).\n",
    "#                     radius=radius,        # The radius values for circle markers (**in \"data space\" units**, by default).\n",
    "#                     fill_color=[\"#ffffff\" for pix in geom1d.pix_x],\n",
    "#                     line_color=[\"#000000\" for pix in geom1d.pix_x],\n",
    "#                     alpha=1.)\n",
    "\n",
    "source = ColumnDataSource(\n",
    "             data=dict(\n",
    "                 x=geom1d.pix_x.value,\n",
    "                 y=geom1d.pix_y.value,\n",
    "                 fill_color=[\"#ffffff\" for pix in geom1d.pix_x],\n",
    "                 line_color=[\"#000000\" for pix in geom1d.pix_x],\n",
    "                 radius=[radius for pix in geom1d.pix_x],\n",
    "                 pe=[0. for pix in geom1d.pix_x],\n",
    "             )\n",
    "         )\n",
    "\n",
    "circles = fig.circle(\"x\",\n",
    "                     \"y\",\n",
    "                     radius=\"radius\",        # The radius values for circle markers (**in \"data space\" units**, by default).\n",
    "                     fill_color=bokeh.transform.transform('pe', color_mapper), # \"fill_color\",\n",
    "                     line_color=bokeh.transform.transform('pe', color_mapper), # \"line_color\",\n",
    "                     source=source)\n",
    "\n",
    "shower_lines = fig.multi_line(xs=[[0, 0],[0, 0]],\n",
    "                              ys=[[0, 0],[0, 0]],\n",
    "                              color=[\"red\", \"green\"],\n",
    "                              line_width=2,\n",
    "                              alpha=0.75)\n",
    "\n",
    "shower_ellipse = fig.ellipse(x=0.,\n",
    "                             y=0.,\n",
    "                             width=0.,\n",
    "                             height=0.,\n",
    "                             angle=0.,\n",
    "                             color=\"red\",\n",
    "                             alpha=0.5)\n",
    "\n",
    "fig.add_tools(hover)\n",
    "\n",
    "# show the results\n",
    "handle = show(fig, notebook_handle=True)\n",
    "\n",
    "# Interactive widget ################\n",
    "\n",
    "@interact(plot_type=[\"raw\", \"ref.\", \"cleaned\", \"diff\", \"1st plane\", \"2nd plane\", \"3rd plane\"],\n",
    "          image_key=image_dict.keys(),\n",
    "          type_of_filtering = list(pywi.processing.filtering.hard_filter.AVAILABLE_TYPE_OF_FILTERING),\n",
    "          wt_threshold_1=(0., 10.),\n",
    "          wt_threshold_2=(0., 10.),\n",
    "          clusters_threshold=0.,\n",
    "          last_scale_treatment = list(pywi.processing.transform.mrtransform_wrapper.AVAILABLE_LAST_SCALE_OPTIONS),\n",
    "          detect_only_positive_structures = False,\n",
    "          use_noise_distribution=True,\n",
    "          kill_isolated_pixels=True)\n",
    "def compute_hillas_and_display(plot_type,\n",
    "                               image_key,\n",
    "                               type_of_filtering = 'hard_filtering',\n",
    "                               wt_threshold_1=3.,\n",
    "                               wt_threshold_2=0.2,\n",
    "                               clusters_threshold=0.2,\n",
    "                               last_scale_treatment = 'drop',\n",
    "                               detect_only_positive_structures = False,\n",
    "                               use_noise_distribution=True,\n",
    "                               kill_isolated_pixels=False):\n",
    "    \n",
    "    # GET IMAGES ###########################\n",
    "    \n",
    "    image = image_dict[image_key]\n",
    "    image.meta['npe'] = np.nansum(image.reference_image)\n",
    "    cam_id = image.meta['cam_id']\n",
    "\n",
    "    filter_thresholds = [wt_threshold_1, wt_threshold_2]\n",
    "    number_of_scales = len(filter_thresholds) + 1\n",
    "    \n",
    "    noise_distribution = empirical_noise_distribution if use_noise_distribution else None\n",
    "    \n",
    "    plot_hillas_params = True\n",
    "    show_background = True\n",
    "    \n",
    "    if plot_type == \"raw\":\n",
    "\n",
    "        img_1d = geometry_converter.image_2d_to_1d(image.input_image, cam_id)\n",
    "        highlight_pixel_mask_1d = np.ones_like(img_1d, dtype=\"bool\")\n",
    "        plot_hillas_params = False\n",
    "        show_background = True\n",
    "\n",
    "    elif plot_type == \"ref.\":\n",
    "\n",
    "        img_1d = geometry_converter.image_2d_to_1d(image.reference_image, cam_id)\n",
    "        highlight_pixel_mask_1d = np.ones_like(img_1d, dtype=\"bool\")\n",
    "        \n",
    "        #reference_image_mask = np.full(reference_image_1d.shape, False)\n",
    "        #reference_image_mask[reference_image_1d > 0] = True\n",
    "        \n",
    "        shower_centroid, shower_angle, shower_length, shower_width, shower_lines_xs, shower_lines_ys = plot_hillas_parameters(geom1d, image=img_1d)\n",
    "        show_background = False\n",
    "\n",
    "    elif plot_type == \"cleaned\":\n",
    "\n",
    "        cleaned_img = wavelet.clean_image(image.input_image,\n",
    "                                          type_of_filtering = type_of_filtering,\n",
    "                                          filter_thresholds = filter_thresholds,\n",
    "                                          clusters_threshold = clusters_threshold,\n",
    "                                          last_scale_treatment = last_scale_treatment,\n",
    "                                          detect_only_positive_structures = detect_only_positive_structures,\n",
    "                                          kill_isolated_pixels = kill_isolated_pixels,\n",
    "                                          noise_distribution = noise_distribution,\n",
    "                                          tmp_files_directory = TMP_DIR)\n",
    "    \n",
    "        if np.nanmax(cleaned_img) == 0:\n",
    "\n",
    "            img_1d = None\n",
    "            plot_hillas_params = False\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            img_1d = geometry_converter.image_2d_to_1d(cleaned_img, cam_id)\n",
    "            highlight_pixel_mask_1d = np.ones_like(img_1d, dtype=\"bool\")\n",
    "            shower_centroid, shower_angle, shower_length, shower_width, shower_lines_xs, shower_lines_ys = plot_hillas_parameters(geom1d, image=img_1d)\n",
    "        \n",
    "        show_background = False\n",
    "\n",
    "    elif plot_type == \"diff\":\n",
    "\n",
    "        cleaned_img = wavelet.clean_image(image.input_image,\n",
    "                                          type_of_filtering = type_of_filtering,\n",
    "                                          filter_thresholds = filter_thresholds,\n",
    "                                          clusters_threshold = clusters_threshold,\n",
    "                                          last_scale_treatment = last_scale_treatment,\n",
    "                                          detect_only_positive_structures = detect_only_positive_structures,\n",
    "                                          kill_isolated_pixels = kill_isolated_pixels,\n",
    "                                          noise_distribution = noise_distribution,\n",
    "                                          tmp_files_directory = TMP_DIR)\n",
    "        \n",
    "        img_1d = geometry_converter.image_2d_to_1d(image.reference_image - cleaned_img, cam_id)\n",
    "        img_1d = np.abs(img_1d)\n",
    "        highlight_pixel_mask_1d = np.ones_like(img_1d, dtype=\"bool\")\n",
    "        plot_hillas_params = False\n",
    "        show_background = False\n",
    "        \n",
    "    elif plot_type == \"1st plane\":\n",
    "\n",
    "        in_planes = wavelets_mrtransform.wavelet_transform(image.input_image,\n",
    "                                                           number_of_scales=number_of_scales,\n",
    "                                                           tmp_files_directory=TMP_DIR,\n",
    "                                                           noise_distribution=noise_distribution)\n",
    "\n",
    "        highlight_pixel_mask = wavelets_mrtransform.filter_planes(in_planes,\n",
    "                                                                  method=type_of_filtering,\n",
    "                                                                  thresholds=filter_thresholds,\n",
    "                                                                  detect_only_positive_structures=detect_only_positive_structures)\n",
    "        highlight_pixel_mask_1d = geometry_converter.image_2d_to_1d(highlight_pixel_mask[0], cam_id)\n",
    "        \n",
    "        img_1d = geometry_converter.image_2d_to_1d(in_planes[0], cam_id)\n",
    "        plot_hillas_params = False\n",
    "        show_background = True\n",
    "        \n",
    "    elif plot_type == \"2nd plane\":\n",
    "\n",
    "        in_planes = wavelets_mrtransform.wavelet_transform(image.input_image,\n",
    "                                                           number_of_scales=number_of_scales,\n",
    "                                                           tmp_files_directory=TMP_DIR,\n",
    "                                                           noise_distribution=noise_distribution)\n",
    "\n",
    "        highlight_pixel_mask = wavelets_mrtransform.filter_planes(in_planes,\n",
    "                                                                  method=type_of_filtering,\n",
    "                                                                  thresholds=filter_thresholds,\n",
    "                                                                  detect_only_positive_structures=detect_only_positive_structures)\n",
    "        highlight_pixel_mask_1d = geometry_converter.image_2d_to_1d(highlight_pixel_mask[1], cam_id)\n",
    "        \n",
    "        img_1d = geometry_converter.image_2d_to_1d(in_planes[1], cam_id)\n",
    "        plot_hillas_params = False\n",
    "        show_background = True\n",
    "        \n",
    "    elif plot_type == \"3rd plane\":\n",
    "\n",
    "        in_planes = wavelets_mrtransform.wavelet_transform(image.input_image,\n",
    "                                                           number_of_scales=number_of_scales,\n",
    "                                                           tmp_files_directory=TMP_DIR,\n",
    "                                                           noise_distribution=noise_distribution)\n",
    "\n",
    "        highlight_pixel_mask = wavelets_mrtransform.filter_planes(in_planes,\n",
    "                                                                  method=type_of_filtering,\n",
    "                                                                  thresholds=filter_thresholds,\n",
    "                                                                  detect_only_positive_structures=detect_only_positive_structures)\n",
    "        highlight_pixel_mask_1d = geometry_converter.image_2d_to_1d(highlight_pixel_mask[2], cam_id)\n",
    "        \n",
    "        img_1d = geometry_converter.image_2d_to_1d(in_planes[2], cam_id)\n",
    "        plot_hillas_params = False\n",
    "        show_background = True\n",
    "    \n",
    "    # Update the plot\n",
    "    if img_1d is None:\n",
    "        circles.data_source.data['fill_color'] = [\"#ffffff\" for color in geom1d.pix_x]\n",
    "        circles.data_source.data['line_color'] = [\"#aaaaaa\" for color in geom1d.pix_x]\n",
    "        circles.data_source.data['radius'] = [radius for pixel in geom1d.pix_x]\n",
    "    else:\n",
    "        circles.data_source.data['pe'] = img_1d\n",
    "        \n",
    "        pix_radius = np.full_like(geom1d.pix_x.value, radius)\n",
    "        pix_radius[highlight_pixel_mask_1d == 0] = radius/2.\n",
    "        circles.data_source.data['radius'] = pix_radius\n",
    "            \n",
    "        color_mapper.low = img_1d.min()\n",
    "        color_mapper.high = img_1d.max()\n",
    "        \n",
    "        if show_background:\n",
    "            color_mapper.palette = palette_1\n",
    "        else:\n",
    "            color_mapper.palette = palette_2\n",
    "        \n",
    "    if not plot_hillas_params:\n",
    "        shower_centroid = (0, 0)\n",
    "        shower_angle = 0.\n",
    "        shower_length = 0.\n",
    "        shower_width = 0.\n",
    "        shower_lines_xs = [[0, 0], [0, 0]]\n",
    "        shower_lines_ys = [[0, 0], [0, 0]]\n",
    "    \n",
    "    shower_lines.data_source.data['xs'] = shower_lines_xs\n",
    "    shower_lines.data_source.data['ys'] = shower_lines_ys\n",
    "\n",
    "    shower_ellipse.glyph.x = shower_centroid[0]\n",
    "    shower_ellipse.glyph.y = shower_centroid[1]\n",
    "    shower_ellipse.glyph.angle = shower_angle\n",
    "    shower_ellipse.glyph.width = shower_length\n",
    "    shower_ellipse.glyph.height =  shower_width\n",
    "        \n",
    "    #print(image.meta)\n",
    "    \n",
    "    if plot_type == \"raw\":\n",
    "        plot_desc = \"calibrated image\"\n",
    "    elif plot_type == \"ref.\":\n",
    "        plot_desc = \"MC image\"\n",
    "    elif plot_type == \"cleaned\":\n",
    "        plot_desc = \"Wavelet clean\"\n",
    "    elif plot_type == \"diff\":\n",
    "        plot_desc = \"MC image - Wavelet clean\"\n",
    "    else:\n",
    "        plot_desc = plot_type\n",
    "        \n",
    "    title.text = \"Run{} Ev{} Tel{} {:0.3f}TeV {}NPE {}\".format(image.meta['run_id'],\n",
    "                                                               image.meta['event_id'],\n",
    "                                                               image.meta['tel_id'],\n",
    "                                                               image.meta['mc_energy'][0],\n",
    "                                                               image.meta['npe'],\n",
    "                                                               plot_desc)\n",
    "    \n",
    "    fig.title = title\n",
    "    \n",
    "    push_notebook(handle=handle)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
